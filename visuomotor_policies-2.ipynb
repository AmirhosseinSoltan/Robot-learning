{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca875003",
   "metadata": {},
   "source": [
    "#### Team members:\n",
    "* achaur2s\n",
    "* asolta2s\n",
    "* gchenc2s\n",
    "* nselva2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a20441",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T19:15:56.614098Z",
     "start_time": "2024-11-06T19:15:54.126101Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f64f76078878014611909be4e3da448c",
     "grade": false,
     "grade_id": "cell-af3beda0aef421f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as distributions\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b82ba82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T19:16:00.325181Z",
     "start_time": "2024-11-06T19:15:56.616422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[classic-control] in /opt/conda/lib/python3.11/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (from gymnasium[classic-control]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from gymnasium[classic-control]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.11/site-packages (from gymnasium[classic-control]) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from gymnasium[classic-control]) (0.0.4)\n",
      "Collecting pygame>=2.1.3 (from gymnasium[classic-control])\n",
      "  Using cached pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Using cached pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install gymnasium[classic-control]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bef47f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcc5c9eb8b701c95d9eb750934fd65b2",
     "grade": false,
     "grade_id": "cell-f5699744cc964552",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Visuomotor Policies\n",
    "\n",
    "In this assignment, you will develop a simple visuomotor policy for solving the simple cart-pole problem. For this, you will use the [gymnasium](https://gymnasium.farama.org/) (which defines the cart-pole environment) as well as PyTorch for implementing and training neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025cbbe8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9643554ccd0ecddfd3a45d51a2ac1b5",
     "grade": false,
     "grade_id": "cell-835bec8d44e0c6de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Policy Network Implementation [30 points]\n",
    "\n",
    "In the cell below, implement the `LearningAgent` class that defines policy and/or value networks (depending on the reinforcement learning algorithm that you want to implement) and allows you to sample actions from the learned policy as well as perform network updates based on experiences.\n",
    "\n",
    "Your network should be defined so that the $s \\in S$ is an image of the cart-pole system and the action space is discrete - move left or move right.\n",
    "\n",
    "Note: If it helps, you are free to incorporate existing implementations of reinforcement learning algorithms, for instance as provided in [Stable Baselines3](https://stable-baselines3.readthedocs.io/en/master/), in your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4851eae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T19:16:07.535194Z",
     "start_time": "2024-11-06T19:16:06.539735Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "450bce8b8123e8851519bde55114c390",
     "grade": true,
     "grade_id": "cell-44637cbf9340d5ac",
     "locked": false,
     "points": 30,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib\n",
    "import math\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "### Define an agent that implements a deep reinforcement learning algorithm of your choice to solve an MDP.\n",
    "### The class should:\n",
    "### * define your policy / value networks\n",
    "### * enable sample actions from the learned policy, and\n",
    "### * enable network updates based on experiences\n",
    "### You will need to update the function signatures so that you can pass appropriate parameters.\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "\n",
    "\n",
    "class LearningAgent(nn.Module):\n",
    "    def __init__(self, obs_space_shape, num_actions):\n",
    "        super(LearningAgent, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.device = device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else\n",
    "            \"mps\" if torch.backends.mps.is_available() else\n",
    "            \"cpu\"\n",
    "        )\n",
    "        self.obs_space_shape = obs_space_shape\n",
    "        self.num_actions = num_actions\n",
    "#         self.policy_net = DQN(self.obs_space_shape[0], self.obs_space_shape[0], self.num_actions).to(self.device)\n",
    "#         self.target_net = DQN(self.obs_space_shape[0], self.obs_space_shape[0], self.num_actions).to(self.device)\n",
    "        self.policy_net = self._create_network(self.obs_space_shape, self.num_actions).to(self.device)\n",
    "        self.target_net = self._create_network(self.obs_space_shape, self.num_actions).to(self.device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        \n",
    "        self.optimizer = optim.AdamW(self.policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "        self.memory = ReplayMemory(10000)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def _create_network(self, input_shape, output_shape):\n",
    "        net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * (input_shape[0] - 8) * (input_shape[1] - 8), 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_shape)  # Output Q-values for each action\n",
    "        )\n",
    "        return net\n",
    "\n",
    "#     def _create_network(self, input_shape, output_shape):\n",
    "#         net = nn.Sequential(\n",
    "#             nn.Linear(input_shape, 64),  # input_shape = 4 for vector input\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, output_shape)  # Output layer for Q-values or class logits\n",
    "#         )\n",
    "#         return net\n",
    "\n",
    "    def sample_action(self,state):\n",
    "        \"\"\"Samples an action from the policy.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return self.policy_net(state).max(1).indices.view(1, 1)\n",
    "\n",
    "#         raise NotImplementedError()\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"Updates the network parameters.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        target_net_state_dict = self.target_net.state_dict()\n",
    "        policy_net_state_dict = self.policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        self.target_net.load_state_dict(target_net_state_dict)\n",
    "        \n",
    "    def optimize_model(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "        # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "        # detailed explanation). This converts batch-array of Transitions\n",
    "        # to Transition of batch-arrays.\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        # Compute a mask of non-final states and concatenate the batch elements\n",
    "        # (a final state would've been the one after which simulation ended)\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                              batch.next_state)), device=self.device, dtype=torch.bool)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                    if s is not None])\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "        # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "        # columns of actions taken. These are the actions which would've been taken\n",
    "        # for each batch state according to policy_net\n",
    "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # Compute V(s_{t+1}) for all next states.\n",
    "        # Expected values of actions for non_final_next_states are computed based\n",
    "        # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "        # This is merged based on the mask, such that we'll have either the expected\n",
    "        # state value or 0 in case the state was final.\n",
    "        next_state_values = torch.zeros(BATCH_SIZE, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            next_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1).values\n",
    "        # Compute the expected Q values\n",
    "        expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "        # Compute Huber loss\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # In-place gradient clipping\n",
    "        torch.nn.utils.clip_grad_value_(self.policy_net.parameters(), 100)\n",
    "        self.optimizer.step()\n",
    "\n",
    "#         raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "742a8178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T19:17:37.298726Z",
     "start_time": "2024-11-06T19:17:37.137728Z"
    }
   },
   "outputs": [],
   "source": [
    "!export XDG_RUNTIME_DIR=/run/user/$(id -u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e792e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T19:16:13.089324Z",
     "start_time": "2024-11-06T19:16:13.077645Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ac49d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b8502ac3995ff04da3ff79eabe9565a6",
     "grade": false,
     "grade_id": "cell-d83c2dca1c108cb7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Agent Training [40 points]\n",
    "\n",
    "Now that your network is defined, implement the reinforcement learning loop for your agent in the cell below. This means that you need to collect experiences of the form $(s_t, a_t, s_{t+1}, r)$ so that you can update your policy network appropriately. How exactly you do the update will depend on the RL algorithm you use.\n",
    "\n",
    "Plot the evolution of the return over the learning process to show that your agent is actually learning. Note, however, that, as reinforcement learning algorithms have randomness associated with them, the results will differ every time you execute the algorithm; thus, you should plot an average of the return (over multiple runs) instead of the return of a single run --- like on the plots shown [here](https://how-do-you-learn.readthedocs.io/en/latest/rl/reinforce.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd4b2fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T14:48:16.381817Z",
     "start_time": "2024-10-31T14:26:27.068862Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93f180d271e526008e50fca05719d185",
     "grade": true,
     "grade_id": "cell-77f7a14c6022a423",
     "locked": false,
     "points": 35,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# creating the cart pole environment in a way that allows us to render the observation as an image\n",
    "env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
    "\n",
    "### You can obtain an image of the current state of the system as follows:\n",
    "###     current_img_state = env.render()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "observation, info = env.reset()\n",
    "current_img_state = env.render()\n",
    "\n",
    "obs_shape = current_img_state.shape\n",
    "action_shape = env.action_space.n\n",
    "\n",
    "agent = LearningAgent((30,70), action_shape)\n",
    "\n",
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "    num_episodes = 200\n",
    "else:\n",
    "    num_episodes = 50\n",
    "episode_durations = []\n",
    "steps_done = 0\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    _, info = env.reset()\n",
    "    img = env.render()\n",
    "    img = Image.fromarray(img, mode='RGB') \n",
    "    # img =  torch.tensor(state, dtype=torch.float32, device=agent.device).unsqueeze(0)\n",
    "    transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), \n",
    "                                    transforms.Resize((70, 70)),\n",
    "                                    transforms.Lambda(lambda img: img.crop((0, 28, img.width, 58))),\n",
    "                                    transforms.ToTensor()])\n",
    "    state = transform(img).squeeze(0).numpy()\n",
    "#     state = rgb_to_grayscale(img)\n",
    "#     state = crop_center(state, 200, 200)\n",
    "#     state = cv2.resize(state, (50, 50), interpolation=cv2.INTER_AREA)\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=agent.device).unsqueeze(0).unsqueeze(0)\n",
    "    for t in count():\n",
    "        sample = random.random()\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "            math.exp(-1. * steps_done / EPS_DECAY)\n",
    "        steps_done += 1\n",
    "        if sample > eps_threshold:\n",
    "            with torch.no_grad():\n",
    "                # t.max(1) will return the largest column value of each row.\n",
    "                # second column on max result is index of where max element was\n",
    "                # found, so we pick action with the larger expected reward.\n",
    "                action = agent.sample_action(state)\n",
    "        else:\n",
    "            action = torch.tensor([[env.action_space.sample()]], device=agent.device, dtype=torch.long)\n",
    "        _, reward, terminated, truncated, _ = env.step(action.item())\n",
    "        observation = env.render()\n",
    "        reward = torch.tensor([reward], device=agent.device)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "#             observation = rgb_to_grayscale(observation)\n",
    "#             observation = crop_center(observation, 200, 200)\n",
    "#             observation = cv2.resize(observation, (50, 50), interpolation=cv2.INTER_AREA)\n",
    "            observation = Image.fromarray(observation, mode='RGB') \n",
    "            transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), \n",
    "                                            transforms.Resize((70, 70)),\n",
    "                                            transforms.Lambda(lambda img: img.crop((0, 28, img.width, 58))),\n",
    "                                           transforms.ToTensor()])\n",
    "            observation = transform(observation).squeeze(0).numpy()\n",
    "            \n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=agent.device).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        agent.memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        agent.optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = agent.target_net.state_dict()\n",
    "        policy_net_state_dict = agent.policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        agent.target_net.load_state_dict(target_net_state_dict)\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    " \n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f507df0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-31T14:25:28.560Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
    "_, info = env.reset()\n",
    "img = env.render()\n",
    "img = Image.fromarray(img, mode='RGB') \n",
    "# img =  torch.tensor(state, dtype=torch.float32, device=agent.device).unsqueeze(0)\n",
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), \n",
    "                                transforms.Resize((70, 70)),\n",
    "                                transforms.Lambda(lambda img: img.crop((0, 28, img.width, 58))), \n",
    "                                transforms.ToTensor()])\n",
    "state = transform(img).squeeze(0).numpy()\n",
    "\n",
    "print(state.shape)\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Visualizing the image\n",
    "plt.imshow(state, cmap='gray' if state.ndim == 2 else None)\n",
    "plt.axis('on')  # Hide the axes\n",
    "plt.grid(color='black', linestyle='-', linewidth=0.5)  # Customize grid color and style\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe8a19",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b310bf40978769ed8a86852a0458925e",
     "grade": true,
     "grade_id": "cell-1363692a5c2587c3",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Discuss the observations from your evaluation here.\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cadd2f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acf1aeab636ea5bae0cbb1b11848ba16",
     "grade": false,
     "grade_id": "cell-6be28454f1d2c5f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Combining Visual and Explicit State Information [30 points]\n",
    "\n",
    "Modify your implementation of the policy network so that it takes both the image and the explicit state information of the system as separate inputs (thus turning the policy into a multimodal policy). Then, update the learning loop accordingly and verify that learning is indeed taking place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eded6a68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T19:17:43.687290Z",
     "start_time": "2024-11-06T19:17:43.459443Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec02c1fd7982dce782e2969b9941c842",
     "grade": true,
     "grade_id": "cell-019e9f9a3f567c09",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib\n",
    "import math\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "### Define an agent that implements a deep reinforcement learning algorithm of your choice to solve an MDP.\n",
    "### The class should:\n",
    "### * define your policy / value networks\n",
    "### * enable sample actions from the learned policy, and\n",
    "### * enable network updates based on experiences\n",
    "### You will need to update the function signatures so that you can pass appropriate parameters.\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'state_image', 'action', 'next_state', 'next_img', 'reward'))\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition.\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class UpdatedLearningAgent(nn.Module):\n",
    "    def __init__(self, obs_space_shape, vector_input_size, num_actions):\n",
    "        super(UpdatedLearningAgent, self).__init__()\n",
    "        \n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else\n",
    "            \"mps\" if torch.backends.mps.is_available() else\n",
    "            \"cpu\"\n",
    "        )\n",
    "        self.obs_space_shape = obs_space_shape\n",
    "        self.vector_input_size = vector_input_size\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        self.policy_net = self._create_network(self.obs_space_shape, self.vector_input_size, self.num_actions).to(self.device)\n",
    "        self.target_net = self._create_network(self.obs_space_shape, self.vector_input_size, self.num_actions).to(self.device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        \n",
    "        self.optimizer = optim.AdamW(self.policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "        self.memory = ReplayMemory(10000)\n",
    "\n",
    "    def _create_network(self, image_input_shape, vector_input_size, output_shape):\n",
    "        # Image processing branch\n",
    "        image_branch = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * (image_input_shape[0] - 8) * (image_input_shape[1] - 8), 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Vector processing branch\n",
    "        vector_branch = nn.Sequential(\n",
    "            nn.Linear(vector_input_size, 128),  # Size can be adjusted\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),  # Size can be adjusted\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Combined layers after concatenation\n",
    "        combined_layers = nn.Sequential(\n",
    "            nn.Linear(256 + 256, 256),  # Combined input size from both branches\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_shape)  # Output Q-values for each action\n",
    "        )\n",
    "\n",
    "        # Create a complete model\n",
    "        return nn.ModuleList([image_branch, vector_branch, combined_layers])\n",
    "\n",
    "    def sample_action(self, img, state):\n",
    "        \"\"\"Samples an action from the policy.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Pass the state through the image branch\n",
    "            image_output = self.policy_net[0](img)  # Image branch output\n",
    "            # Pass the vector through the vector branch\n",
    "            vector_output = self.policy_net[1](state)  # Vector branch output\n",
    "            # Concatenate outputs\n",
    "            combined_output = torch.cat((image_output, vector_output), dim=1)\n",
    "            # Return the action with the largest expected reward\n",
    "            return self.policy_net[2](combined_output).max(1).indices.view(1, 1)\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"Updates the network parameters.\"\"\"\n",
    "        target_net_state_dict = self.target_net.state_dict()\n",
    "        policy_net_state_dict = self.policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key] * TAU + target_net_state_dict[key] * (1 - TAU)\n",
    "        self.target_net.load_state_dict(target_net_state_dict)\n",
    "        \n",
    "    def optimize_model(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=self.device, dtype=torch.bool)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        state_img_batch = torch.cat(batch.state_image)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "        \n",
    "        # Compute state-action values\n",
    "        image_output = self.policy_net[0](state_img_batch)  # Get output from image branch\n",
    "        vector_output = self.policy_net[1](state_batch)  # Get output from vector branch\n",
    "        combined_output = torch.cat((image_output, vector_output), dim=1)  # Concatenate the outputs\n",
    "\n",
    "        state_action_values = self.policy_net[2](combined_output).gather(1, action_batch)  # Now gather actions from combined output\n",
    "\n",
    "        # Compute expected state values for next states\n",
    "        next_state_values = torch.zeros(BATCH_SIZE, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            # Process next states through both networks to get values\n",
    "            non_final_next_images = state_img_batch[non_final_mask]  # Get the corresponding vector inputs\n",
    "            next_image_outputs = self.target_net[0](non_final_next_images)  # Process next states through image branch\n",
    "            next_vector_outputs = self.target_net[1](non_final_next_states)  # Process next vector inputs through vector branch\n",
    "            next_combined_output = torch.cat((next_image_outputs, next_vector_outputs), dim=1)  # Concatenate next outputs\n",
    "\n",
    "            next_state_values[non_final_mask] = self.target_net[2](next_combined_output).max(1).values  # Use combined output for target values\n",
    "\n",
    "        # Compute expected Q values\n",
    "        expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "        # Compute Huber loss\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(self.policy_net.parameters(), 100)\n",
    "        self.optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d044c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-06T19:18:18.832Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b649aeb3fa58ebbe944bf1ebf60ac919",
     "grade": true,
     "grade_id": "cell-a04c1b0a08a24684",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# creating the cart pole environment in a way that allows us to render the observation as an image\n",
    "env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
    "\n",
    "### You can obtain an image of the current state of the system as follows:\n",
    "###     current_img_state = env.render()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "observation, info = env.reset()\n",
    "current_img_state = env.render()\n",
    "reward_plot = []\n",
    "obs_shape = observation.shape[0]\n",
    "action_shape = env.action_space.n\n",
    "\n",
    "agent = UpdatedLearningAgent((30,70),obs_shape, action_shape)\n",
    "\n",
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "    num_episodes = 600\n",
    "else:\n",
    "    num_episodes = 500\n",
    "episode_durations = []\n",
    "steps_done = 0\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=agent.device).unsqueeze(0)\n",
    "    img = env.render()\n",
    "    img = Image.fromarray(img, mode='RGB') \n",
    "    # img =  torch.tensor(state, dtype=torch.float32, device=agent.device).unsqueeze(0)\n",
    "    transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), \n",
    "                                    transforms.Resize((70, 70)),\n",
    "                                    transforms.Lambda(lambda img: img.crop((0, 28, img.width, 58))),\n",
    "                                    transforms.ToTensor()])\n",
    "    img = transform(img).squeeze(0).numpy()\n",
    "    img = torch.tensor(img, dtype=torch.float32, device=agent.device).unsqueeze(0).unsqueeze(0)\n",
    "    for t in count():\n",
    "        sample = random.random()\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "            math.exp(-1. * steps_done / EPS_DECAY)\n",
    "        steps_done += 1\n",
    "        if sample > eps_threshold:\n",
    "            with torch.no_grad():\n",
    "                # t.max(1) will return the largest column value of each row.\n",
    "                # second column on max result is index of where max element was\n",
    "                # found, so we pick action with the larger expected reward.\n",
    "                action = agent.sample_action(img, state)\n",
    "        else:\n",
    "            action = torch.tensor([[env.action_space.sample()]], device=agent.device, dtype=torch.long)\n",
    "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "        obs_img = env.render()\n",
    "        reward = torch.tensor([reward], device=agent.device)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        if terminated:\n",
    "            next_state = None\n",
    "            next_img = None\n",
    "        else:\n",
    "#             observation = rgb_to_grayscale(observation)\n",
    "#             observation = crop_center(observation, 200, 200)\n",
    "#             observation = cv2.resize(observation, (50, 50), interpolation=cv2.INTER_AREA)\n",
    "            obs_img = Image.fromarray(obs_img, mode='RGB') \n",
    "            transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), \n",
    "                                            transforms.Resize((70, 70)),\n",
    "                                            transforms.Lambda(lambda img: img.crop((0, 28, img.width, 58))),\n",
    "                                           transforms.ToTensor()])\n",
    "            obs_img = transform(obs_img).squeeze(0).numpy()\n",
    "            \n",
    "            next_img = torch.tensor(obs_img, dtype=torch.float32, device=agent.device).unsqueeze(0).unsqueeze(0)\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=agent.device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        agent.memory.push(state, img, action, next_state, next_img, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "        img = next_img\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        agent.optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = agent.target_net.state_dict()\n",
    "        policy_net_state_dict = agent.policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        agent.target_net.load_state_dict(target_net_state_dict)\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            reward_plot.append(i_episode)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    " \n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d3d10a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e1d5fab13029132a89e6505cd2aaa1c",
     "grade": true,
     "grade_id": "cell-beb3f26bb8ee791f",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Has the second modality changed the behaviour of the agent? Discuss the observations from your evaluation here.\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
