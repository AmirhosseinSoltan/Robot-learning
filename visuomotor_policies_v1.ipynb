{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca875003",
   "metadata": {},
   "source": [
    "#### Team members:\n",
    "* ...\n",
    "* ...\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a20441",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:19:08.168693Z",
     "start_time": "2024-10-27T13:19:05.833770Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f64f76078878014611909be4e3da448c",
     "grade": false,
     "grade_id": "cell-af3beda0aef421f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as distributions\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b82ba82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T12:46:43.160912Z",
     "start_time": "2024-10-27T12:46:40.271450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[classic-control] in /opt/conda/lib/python3.11/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (from gymnasium[classic-control]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from gymnasium[classic-control]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.11/site-packages (from gymnasium[classic-control]) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from gymnasium[classic-control]) (0.0.4)\n",
      "Collecting pygame>=2.1.3 (from gymnasium[classic-control])\n",
      "  Using cached pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Using cached pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install gymnasium[classic-control]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bef47f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcc5c9eb8b701c95d9eb750934fd65b2",
     "grade": false,
     "grade_id": "cell-f5699744cc964552",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Visuomotor Policies\n",
    "\n",
    "In this assignment, you will develop a simple visuomotor policy for solving the simple cart-pole problem. For this, you will use the [gymnasium](https://gymnasium.farama.org/) (which defines the cart-pole environment) as well as PyTorch for implementing and training neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025cbbe8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9643554ccd0ecddfd3a45d51a2ac1b5",
     "grade": false,
     "grade_id": "cell-835bec8d44e0c6de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Policy Network Implementation [30 points]\n",
    "\n",
    "In the cell below, implement the `LearningAgent` class that defines policy and/or value networks (depending on the reinforcement learning algorithm that you want to implement) and allows you to sample actions from the learned policy as well as perform network updates based on experiences.\n",
    "\n",
    "Your network should be defined so that the $s \\in S$ is an image of the cart-pole system and the action space is discrete - move left or move right.\n",
    "\n",
    "Note: If it helps, you are free to incorporate existing implementations of reinforcement learning algorithms, for instance as provided in [Stable Baselines3](https://stable-baselines3.readthedocs.io/en/master/), in your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4851eae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:46:40.767299Z",
     "start_time": "2024-10-27T13:46:40.743236Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "450bce8b8123e8851519bde55114c390",
     "grade": true,
     "grade_id": "cell-44637cbf9340d5ac",
     "locked": false,
     "points": 30,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import torch.nn.functional as F\n",
    "### Define an agent that implements a deep reinforcement learning algorithm of your choice to solve an MDP.\n",
    "### The class should:\n",
    "### * define your policy / value networks\n",
    "### * enable sample actions from the learned policy, and\n",
    "### * enable network updates based on experiences\n",
    "### You will need to update the function signatures so that you can pass appropriate parameters.\n",
    "# BATCH_SIZE = 128\n",
    "# GAMMA = 0.99\n",
    "# EPS_START = 0.9\n",
    "# EPS_END = 0.05\n",
    "# EPS_DECAY = 1000\n",
    "# TAU = 0.005\n",
    "# LR = 1e-4\n",
    "\n",
    "############ HYPERPARAMETERS ##############\n",
    "BATCH_SIZE = 128 # original = 128\n",
    "GAMMA = 0.999 # original = 0.999\n",
    "EPS_START = 0.9 # original = 0.9\n",
    "EPS_END = 0.01 # original = 0.05\n",
    "EPS_DECAY = 3000 # original = 200\n",
    "TARGET_UPDATE = 50 # original = 10\n",
    "MEMORY_SIZE = 100000 # original = 10000\n",
    "END_SCORE = 200 # 200 for Cartpole-v0\n",
    "TRAINING_STOP = 142 # threshold for training stop\n",
    "N_EPISODES = 50000 # total episodes to be run\n",
    "LAST_EPISODES_NUM = 20 # number of episodes for stopping training\n",
    "FRAMES = 2 # state is the number of last frames: the more frames, \n",
    "# the more the state is detailed (still Markovian)\n",
    "RESIZE_PIXELS = 60 # Downsample image to this number of pixels\n",
    "\n",
    "# ---- CONVOLUTIONAL NEURAL NETWORK ----\n",
    "HIDDEN_LAYER_1 = 64\n",
    "HIDDEN_LAYER_2 = 64 \n",
    "HIDDEN_LAYER_3 = 32\n",
    "KERNEL_SIZE = 5 # original = 5\n",
    "STRIDE = 2 # original = 2\n",
    "# --------------------------------------\n",
    "\n",
    "GRAYSCALE = True # False is RGB\n",
    "LOAD_MODEL = False # If we want to load the model, Default= False\n",
    "USE_CUDA = True # If we want to use GPU (powerful one needed!)\n",
    "############################################\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, HIDDEN_LAYER_1, kernel_size=KERNEL_SIZE, stride=STRIDE) \n",
    "        self.bn1 = nn.BatchNorm2d(HIDDEN_LAYER_1)\n",
    "        self.conv2 = nn.Conv2d(HIDDEN_LAYER_1, HIDDEN_LAYER_2, kernel_size=KERNEL_SIZE, stride=STRIDE)\n",
    "        self.bn2 = nn.BatchNorm2d(HIDDEN_LAYER_2)\n",
    "        self.conv3 = nn.Conv2d(HIDDEN_LAYER_2, HIDDEN_LAYER_3, kernel_size=KERNEL_SIZE, stride=STRIDE)\n",
    "        self.bn3 = nn.BatchNorm2d(HIDDEN_LAYER_3)\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = KERNEL_SIZE, stride = STRIDE):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        nn.Dropout()\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))\n",
    "\n",
    "class LearningAgent(nn.Module):\n",
    "    def __init__(self, obs_space_shape, num_actions):\n",
    "        super(LearningAgent, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.device = device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else\n",
    "            \"mps\" if torch.backends.mps.is_available() else\n",
    "            \"cpu\"\n",
    "        )\n",
    "        self.obs_space_shape = obs_space_shape\n",
    "        self.num_actions = num_actions\n",
    "#         self.policy_net = DQN(self.obs_space_shape[0], self.obs_space_shape[0], self.num_actions).to(self.device)\n",
    "#         self.target_net = DQN(self.obs_space_shape[0], self.obs_space_shape[0], self.num_actions).to(self.device)\n",
    "        self.policy_net = self._create_network(self.obs_space_shape, self.num_actions).to(self.device)\n",
    "        self.target_net = self._create_network(self.obs_space_shape, self.num_actions).to(self.device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        \n",
    "        self.optimizer = optim.AdamW(self.policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "        self.memory = ReplayMemory(10000)\n",
    "    \n",
    "    \n",
    "        \n",
    "    def _create_network(self, input_shape, output_shape):\n",
    "        net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * (input_shape[0] - 4) * (input_shape[1] - 4), 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_shape)  # Output Q-values for each action\n",
    "        )\n",
    "        return net\n",
    "\n",
    "#     def _create_network(self, input_shape, output_shape):\n",
    "#         net = nn.Sequential(\n",
    "#             nn.Linear(input_shape, 64),  # input_shape = 4 for vector input\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, output_shape)  # Output layer for Q-values or class logits\n",
    "#         )\n",
    "#         return net\n",
    "\n",
    "    def sample_action(self,state):\n",
    "        \"\"\"Samples an action from the policy.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return self.policy_net(state).max(1).indices.view(1, 1)\n",
    "\n",
    "#         raise NotImplementedError()\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"Updates the network parameters.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        target_net_state_dict = self.target_net.state_dict()\n",
    "        policy_net_state_dict = self.policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        self.target_net.load_state_dict(target_net_state_dict)\n",
    "        \n",
    "    def optimize_model():\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "        # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "        # detailed explanation). This converts batch-array of Transitions\n",
    "        # to Transition of batch-arrays.\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "        # Compute a mask of non-final states and concatenate the batch elements\n",
    "        # (a final state would've been the one after which simulation ended)\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                              batch.next_state)), device=self.device, dtype=torch.bool)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                    if s is not None])\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "        # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "        # columns of actions taken. These are the actions which would've been taken\n",
    "        # for each batch state according to policy_net\n",
    "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # Compute V(s_{t+1}) for all next states.\n",
    "        # Expected values of actions for non_final_next_states are computed based\n",
    "        # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "        # This is merged based on the mask, such that we'll have either the expected\n",
    "        # state value or 0 in case the state was final.\n",
    "        next_state_values = torch.zeros(BATCH_SIZE, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            next_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1).values\n",
    "        # Compute the expected Q values\n",
    "        expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "        # Compute Huber loss\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # In-place gradient clipping\n",
    "        torch.nn.utils.clip_grad_value_(self.policy_net.parameters(), 100)\n",
    "        self.optimizer.step()\n",
    "\n",
    "#         raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742a8178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T11:32:16.695882Z",
     "start_time": "2024-10-24T11:32:16.540471Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e64ac49d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b8502ac3995ff04da3ff79eabe9565a6",
     "grade": false,
     "grade_id": "cell-d83c2dca1c108cb7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Agent Training [40 points]\n",
    "\n",
    "Now that your network is defined, implement the reinforcement learning loop for your agent in the cell below. This means that you need to collect experiences of the form $(s_t, a_t, s_{t+1}, r)$ so that you can update your policy network appropriately. How exactly you do the update will depend on the RL algorithm you use.\n",
    "\n",
    "Plot the evolution of the return over the learning process to show that your agent is actually learning. Note, however, that, as reinforcement learning algorithms have randomness associated with them, the results will differ every time you execute the algorithm; thus, you should plot an average of the return (over multiple runs) instead of the return of a single run --- like on the plots shown [here](https://how-do-you-learn.readthedocs.io/en/latest/rl/reinforce.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd4b2fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:12:56.502550Z",
     "start_time": "2024-10-27T13:12:56.283666Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93f180d271e526008e50fca05719d185",
     "grade": true,
     "grade_id": "cell-77f7a14c6022a423",
     "locked": false,
     "points": 35,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'memory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(observation, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39magent\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Store the transition in memory\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mmemory\u001b[49m\u001b[38;5;241m.\u001b[39mpush(state, action, next_state, reward)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Move to the next state\u001b[39;00m\n\u001b[1;32m     41\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n",
      "\u001b[0;31mNameError\u001b[0m: name 'memory' is not defined"
     ]
    }
   ],
   "source": [
    "!export XDG_RUNTIME_DIR=/run/user/$(id -u)\n",
    "# creating the cart pole environment in a way that allows us to render the observation as an image\n",
    "env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
    "\n",
    "### You can obtain an image of the current state of the system as follows:\n",
    "###     current_img_state = env.render()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "observation, info = env.reset()\n",
    "current_img_state = env.render()\n",
    "\n",
    "obs_shape = observation.shape[0]\n",
    "action_shape = env.action_space.n\n",
    "\n",
    "agent = LearningAgent(obs_shape, action_shape)\n",
    "\n",
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "    num_episodes = 600\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=agent.device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        action = agent.sample_action(state)\n",
    "        observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=agent.device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=agent.device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        self.memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "735e5bac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:46:46.563622Z",
     "start_time": "2024-10-27T13:46:44.410029Z"
    }
   },
   "outputs": [],
   "source": [
    "def rgb_to_grayscale(rgb_array):\n",
    "    # Convert RGB to grayscale using the luminance formula\n",
    "    grayscale = 0.2989 * rgb_array[:, :, 0] + 0.5870 * rgb_array[:, :, 1] + 0.1140 * rgb_array[:, :, 2]\n",
    "    return grayscale\n",
    "def crop_center(image, crop_height, crop_width):\n",
    "    # Get the center coordinates of the image\n",
    "    center_y, center_x = image.shape[0] // 2, image.shape[1] // 2\n",
    "    # Calculate cropping coordinates\n",
    "    start_y = max(center_y - crop_height // 2, 0)\n",
    "    start_x = max(center_x - crop_width // 2, 0)\n",
    "    end_y = start_y + crop_height\n",
    "    end_x = start_x + crop_width\n",
    "    # Crop the image\n",
    "    return image[start_y:end_y, start_x:end_x]\n",
    "\n",
    "!export XDG_RUNTIME_DIR=/run/user/$(id -u)\n",
    "# creating the cart pole environment in a way that allows us to render the observation as an image\n",
    "env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
    "observation, info = env.reset()\n",
    "current_img_state = env.render()\n",
    "img = rgb_to_grayscale(current_img_state)\n",
    "img = crop_center(img, 100,100)\n",
    "obs_shape = img.shape\n",
    "action_shape = env.action_space.n\n",
    "\n",
    "agent = LearningAgent(obs_shape, action_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df931bc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:46:46.651616Z",
     "start_time": "2024-10-27T13:46:46.566626Z"
    }
   },
   "outputs": [],
   "source": [
    "state_tensor = torch.FloatTensor(img).to(next(agent.parameters()))  # Move to the same device as the agent\n",
    "\n",
    "# Add a batch dimension and permute to correct the shape\n",
    "state_tensor = torch.FloatTensor(img).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Sample action using the agent's method\n",
    "action = agent.policy_net(state_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c1cd727",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T13:45:40.693964Z",
     "start_time": "2024-10-27T13:45:40.687174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d10b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T14:02:59.534415Z",
     "start_time": "2024-10-24T14:02:59.522556Z"
    }
   },
   "outputs": [],
   "source": [
    "array_shape = (10, 10, 3)\n",
    "array = np.zeros(array_shape)  # This creates a NumPy array filled with zeros\n",
    "\n",
    "# Convert the NumPy array to a PyTorch tensor\n",
    "state_tensor = torch.FloatTensor(array).to(next(agent.parameters()).device)  # Move to the same device as the agent\n",
    "\n",
    "# Add a batch dimension and permute to correct the shape\n",
    "state_tensor = state_tensor.permute(2, 0, 1).unsqueeze(0)  # New shape will be [1, 3, 10, 10]\n",
    "\n",
    "# Sample action using the agent's method\n",
    "action = agent.sample_action(state_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac9269ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T13:58:29.651434Z",
     "start_time": "2024-10-24T13:58:29.634043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f507df0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T11:48:04.114213Z",
     "start_time": "2024-10-24T11:48:03.861525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhQAAAGOCAYAAADPb5pdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5QUlEQVR4nO3dfXCU9b3//9du7gPZTQMmmxySiLcQufOAhh0tx0pKwJQjNWdGLAX0MDDSjb9CWsukg9xo23g4/VWrE6GdY8XOmGrpER0ZRQNoOP4MiLF8uVOOcDhNLGxi5UsWornbvX5/YLauBGRzXezmYp+Pzmcme30+1+7nuhrcd96fm8thGIYhAAAAE5zx7gAAALA/AgoAAGAaAQUAADCNgAIAAJhGQAEAAEwjoAAAAKYRUAAAANMIKAAAgGnJ8e4AAACXg66uLvX09Jh+n9TUVKWnp1vQo9gioAAAwKSuri6NLh4uf3vQ9Ht5PB4dO3bMdkEFAQUAACb19PTI3x7UseZiubIGP5sgcDqk0ZP/op6eHgIKAAASlSvLaSqgsLPEvGoAAC6BoBEyXaJRW1urm266SVlZWcrNzdWcOXN0+PDhiDa33XabHA5HRLn//vsj2rS0tKiiokKZmZnKzc3Vgw8+qL6+vqj6QoYCAACLhGQopME/xDvacxsbG+Xz+XTTTTepr69PP/3pTzVjxgwdOnRIw4YNC7dbvHixHn744fDrzMzM8M/BYFAVFRXyeDx65513dOLECS1YsEApKSn6xS9+cdF9IaAAAMCmtm7dGvF648aNys3NVXNzs6ZNmxY+npmZKY/HM+B7vPHGGzp06JC2bdumvLw8TZo0SY888ohWrFihNWvWKDU19aL6wpAHAAAWCVnwP0kKBAIRpbu7+6I+v6OjQ5KUk5MTcfy5557TyJEjNW7cONXU1Oizzz4L1zU1NWn8+PHKy8sLHysvL1cgENDBgwcv+trJUAAAYJGgYShoDH7Io//cwsLCiOOrV6/WmjVrLnhuKBTSsmXLdMstt2jcuHHh49/73vdUXFysgoIC7du3TytWrNDhw4f14osvSpL8fn9EMCEp/Nrv91903wkoAAAYYlpbW+VyucKv09LSvvYcn8+nAwcO6O233444vmTJkvDP48ePV35+vqZPn66jR4/q6quvtqzPDHkAAGCR/kmZZookuVyuiPJ1AUVVVZW2bNmiN998U6NGjbpg29LSUknSkSNHJJ3dSKutrS2iTf/r8827GAgBBQAAFgnJUNBEiXaVh2EYqqqq0ubNm7Vjxw6NHj36a8/Zu3evJCk/P1+S5PV6tX//frW3t4fbNDQ0yOVyqaSk5KL7wpAHAAAWifWyUZ/Pp/r6er388svKysoKz3lwu93KyMjQ0aNHVV9frzvuuEMjRozQvn37tHz5ck2bNk0TJkyQJM2YMUMlJSWaP3++1q1bJ7/fr5UrV8rn813UUEs/h2GYmD0CAAAUCATkdrt19EOPskzslHn6dEhXj/Gro6MjYg7F+TgcjgGPP/PMM7r33nvV2tqq73//+zpw4IA6OztVWFio7373u1q5cmXE+//lL3/R0qVL9dZbb2nYsGFauHChHn30USUnX3zegYACAACT+gOK//4gz3RAcd3YtosOKIYShjwAALBI6Iti5ny7YlImAAAwjQwFAAAW6V+tYeZ8uyKgAADAIkHjbDFzvl0x5AEAAEwjQwEAgEUSeVImAQUAABYJyaGgBt4b4mLPtyuGPAAAgGlkKAAAsEjIOFvMnG9XBBQAAFgkaHLIw8y58UZAAQCARRI5oGAOBQAAMI0MBQAAFgkZDoUME6s8TJwbbwQUAABYhCEPAAAAE8hQAABgkaCcCpr4Wz1oYV9ijYACAACLGCbnUBg2nkPBkAcAADCNDAUAABZJ5EmZBBQAAFgkaDgVNEzMobDx1tsMeQAAANPIUAAAYJGQHAqZ+Fs9JPumKAgoAACwCHMoAACAaebnUNg3Q8EcCgAAYBoZCgAALHJ2DoWJh4Mx5AEAAEImt96286RMhjwAAIBpZCgAALBIIk/KJKAAAMAiITkTdh8KhjwAAIBpZCgAALBI0HAoaOIR5GbOjTcCCgAALBI0ucojyJAHAABIZHENKOrq6nTllVcqPT1dpaWlevfdd+PZHQAATAkZTtPFruLW8xdeeEHV1dVavXq13n//fU2cOFHl5eVqb2+PV5cAADClf8jDTLGruPX8V7/6lRYvXqz77rtPJSUl2rBhgzIzM/W73/0uXl0CAMCUkP4+MXMwJRTvCzAhLpMye3p61NzcrJqamvAxp9OpsrIyNTU1fe35oVBIx48fV1ZWlhwO+86IBQBceoZh6PTp0yooKJDTad8MwFAXl4Dib3/7m4LBoPLy8iKO5+Xl6cMPPzynfXd3t7q7u8Ov//rXv6qkpOSS9xMAcPlobW3VqFGjLulnmN/Yyr4Bjy2WjdbW1mrt2rXnHG9tbZXL5YpDjwAAdhEIBFRYWKisrKxL/lnmt94moIjKyJEjlZSUpLa2tojjbW1t8ng857SvqalRdXV1+HX/L4fL5SKgAABcFIbIL624hEKpqamaPHmytm/fHj4WCoW0fft2eb3ec9qnpaWFgweCCADAUBWSw3Sxq7gNeVRXV2vhwoWaMmWKbr75Zj3++OPq7OzUfffdF68uAQBgCkMecXD33Xfrk08+0apVq+T3+zVp0iRt3br1nImaAABg6IvrpMyqqipVVVXFswsAAFjG/LM8yFAAAJDwQoZDIRNPDDVzbrzZNxQCAABDBhkKAAAsEjI55MHGVgAAwPQTQ+38tFECCgAALBKUQ0ETe0mYOTfe7BsKAQCAIYMMBQAAFmHIAwAAmBaUuWGLoHVdiTn7hkIAAGDIIEMBAIBFGPIAAACmJfLDwezbcwAAMGSQoQAAwCKGHAqZmJRp2HgfCgIKAAAswpAHAACACWQoAACwCI8vBwAApgW/eNqomRKN2tpa3XTTTcrKylJubq7mzJmjw4cPR7Tp6uqSz+fTiBEjNHz4cFVWVqqtrS2iTUtLiyoqKpSZmanc3Fw9+OCD6uvri6ovBBQAAFikP0NhpkSjsbFRPp9Pu3btUkNDg3p7ezVjxgx1dnaG2yxfvlyvvPKKNm3apMbGRh0/flx33XVXuD4YDKqiokI9PT1655139Oyzz2rjxo1atWpVVH1xGIZhRHXGEBAIBOR2u9XR0SGXyxXv7gAAhrBYfGf0f8b/8/adShueMuj36T7TqydufXnQff3kk0+Um5urxsZGTZs2TR0dHbriiitUX1+vf/mXf5Ekffjhhxo7dqyampo0depUvfbaa/rOd76j48ePKy8vT5K0YcMGrVixQp988olSU1Mv6rPJUAAAYJGQnKaLGR0dHZKknJwcSVJzc7N6e3tVVlYWbjNmzBgVFRWpqalJktTU1KTx48eHgwlJKi8vVyAQ0MGDBy/6s5mUCQCARYKGQ0ETEyv7zw0EAhHH09LSlJaWdsFzQ6GQli1bpltuuUXjxo2TJPn9fqWmpio7OzuibV5envx+f7jNl4OJ/vr+uotFhgIAgCGmsLBQbrc7XGpra7/2HJ/PpwMHDuj555+PQQ/PZXlAsWbNGjkcjogyZsyYcP3FzDYFAMCOrJqU2draqo6OjnCpqam54OdWVVVpy5YtevPNNzVq1KjwcY/Ho56eHp06dSqifVtbmzweT7jNV7+H+1/3t7kYlyRDccMNN+jEiRPh8vbbb4frvm62KQAAdmV88bTRwRbji50yXS5XRDnfcIdhGKqqqtLmzZu1Y8cOjR49OqJ+8uTJSklJ0fbt28PHDh8+rJaWFnm9XkmS1+vV/v371d7eHm7T0NAgl8ulkpKSi772SzKHIjk5ecCopqOjQ08//bTq6+t1++23S5KeeeYZjR07Vrt27dLUqVMvRXcAALgs+Xw+1dfX6+WXX1ZWVlZ4zoPb7VZGRobcbrcWLVqk6upq5eTkyOVy6YEHHpDX6w1/586YMUMlJSWaP3++1q1bJ7/fr5UrV8rn833tvI0vuyQZio8++kgFBQW66qqrNG/ePLW0tEi6uNmmAADYVVAO0yUa69evV0dHh2677Tbl5+eHywsvvBBu89hjj+k73/mOKisrNW3aNHk8Hr344ovh+qSkJG3ZskVJSUnyer36/ve/rwULFujhhx+Oqi+WZyhKS0u1ceNGXX/99Tpx4oTWrl2rb37zmzpw4MBFzTYdSHd3t7q7u8Ovvzr7FQCAoSBkmNs+OxTlzlAXs5VUenq66urqVFdXd942xcXFevXVV6P78K+wPKCYNWtW+OcJEyaotLRUxcXF+uMf/6iMjIxBvWdtba3Wrl1rVRcBAIDFLvmy0ezsbF133XU6cuTIRc02HUhNTU3EbNfW1tZL3GsAAKJnZkJmf7GrS97zM2fO6OjRo8rPz7+o2aYDSUtLO2fGKwAAQ01IDtPFriwf8vjxj3+s2bNnq7i4WMePH9fq1auVlJSke+6556JmmwIAYFdW7ZRpR5YHFB9//LHuueceffrpp7riiit06623ateuXbriiisknZ1t6nQ6VVlZqe7ubpWXl+upp56yuhsAACCGLA8ovm7Lz4uZbQoAgB2ZnQdh5zkUPBwMAACLhOQwt2zUxnMo7BsKAQCAIYMMBQAAFjFMrtQwbJyhIKAAAMAiX35i6GDPtyuGPAAAgGlkKAAAsAirPAAAgGkMeQAAAJhAhgIAAIuYfR6HnfehIKAAAMAiiTzkQUABAIBFEjmgYA4FAAAwjQwFAAAWSeQMBQEFAAAWSeSAgiEPAABgGhkKAAAsYsjc0k/Duq7EHAEFAAAWYcgDAADABDIUAABYJJEzFAQUAABYJJEDCoY8AACAaWQoAACwCBmKKOzcuVOzZ89WQUGBHA6HXnrppYh6wzC0atUq5efnKyMjQ2VlZfroo48i2pw8eVLz5s2Ty+VSdna2Fi1apDNnzpi6EAAA4s0wHKaLXUUdUHR2dmrixImqq6sbsH7dunV64okntGHDBu3evVvDhg1TeXm5urq6wm3mzZungwcPqqGhQVu2bNHOnTu1ZMmSwV8FAABDQP/jy80Uu4p6yGPWrFmaNWvWgHWGYejxxx/XypUrdeedd0qSfv/73ysvL08vvfSS5s6dqw8++EBbt27Vnj17NGXKFEnSk08+qTvuuEO//OUvVVBQYOJyAABAPFg6KfPYsWPy+/0qKysLH3O73SotLVVTU5MkqampSdnZ2eFgQpLKysrkdDq1e/duK7sDAEBM9c+hMFPsytJJmX6/X5KUl5cXcTwvLy9c5/f7lZubG9mJ5GTl5OSE23xVd3e3uru7w68DgYCV3QYAwBJm50Ek1ByKeKitrZXb7Q6XwsLCeHcJAAB8iaUBhcfjkSS1tbVFHG9rawvXeTwetbe3R9T39fXp5MmT4TZfVVNTo46OjnBpbW21stsAAFgikYc8LA0oRo8eLY/Ho+3bt4ePBQIB7d69W16vV5Lk9Xp16tQpNTc3h9vs2LFDoVBIpaWlA75vWlqaXC5XRAEAYKhJ5GWjUc+hOHPmjI4cORJ+fezYMe3du1c5OTkqKirSsmXL9LOf/UzXXnutRo8erYceekgFBQWaM2eOJGns2LGaOXOmFi9erA0bNqi3t1dVVVWaO3cuKzwAALCpqAOK9957T9/61rfCr6urqyVJCxcu1MaNG/WTn/xEnZ2dWrJkiU6dOqVbb71VW7duVXp6evic5557TlVVVZo+fbqcTqcqKyv1xBNPWHA5AADEj2Fy2MLOGQqHYRhGvDsRrUAgILfbrY6ODoY/AAAXFIvvjP7PuPFP1UrKTBv0+wQ/69af/+VXtvx+s8UqDwAAMLTxcDAAACwSkkMOE9tnJ9TW2wAAYGCJvLEVAQUAABYJGQ45eHw5AADA4JChAADAIoZxtpg5364IKAAAsEgiz6FgyAMAAJhGhgIAAIskcoaCgAIAAIuwygMAAMAEMhQAAFiEVR4AAMC0swGFmTkUFnYmxhjyAAAAppGhAADAIqzyAAAAphlfFDPn2xUBBQAAFknkDAVzKAAAgGlkKAAAsEoCj3kQUAAAYBWTQx5iyAMAACQyMhQAAFiEnTIBAIBprPKIws6dOzV79mwVFBTI4XDopZdeiqi/99575XA4IsrMmTMj2pw8eVLz5s2Ty+VSdna2Fi1apDNnzpi6EAAAEs1Q+k6OOqDo7OzUxIkTVVdXd942M2fO1IkTJ8LlD3/4Q0T9vHnzdPDgQTU0NGjLli3auXOnlixZEnXnAQAYUgyH+RKFofSdHPWQx6xZszRr1qwLtklLS5PH4xmw7oMPPtDWrVu1Z88eTZkyRZL05JNP6o477tAvf/lLFRQURNslAACGhFjPoRhK38mXZJXHW2+9pdzcXF1//fVaunSpPv3003BdU1OTsrOzwx2XpLKyMjmdTu3evXvA9+vu7lYgEIgoAAAMOYYFRTrnO6+7u3vQXbL6O/l8LA8oZs6cqd///vfavn27/u3f/k2NjY2aNWuWgsGgJMnv9ys3NzfinOTkZOXk5Mjv9w/4nrW1tXK73eFSWFhodbcBABgyCgsLI773amtrB/U+l+I7+XwsX+Uxd+7c8M/jx4/XhAkTdPXVV+utt97S9OnTB/WeNTU1qq6uDr8OBAIEFQCAIceqVR6tra1yuVzh42lpaYN6v0vxnXw+l3xjq6uuukojR47UkSNHJEkej0ft7e0Rbfr6+nTy5MnzjvGkpaXJ5XJFFAAAhiSTwx2SzvnOG2xA8VVWfCefzyUPKD7++GN9+umnys/PlyR5vV6dOnVKzc3N4TY7duxQKBRSaWnppe4OAAAJ61J+J0c95HHmzJlwZCNJx44d0969e5WTk6OcnBytXbtWlZWV8ng8Onr0qH7yk5/ommuuUXl5uSRp7NixmjlzphYvXqwNGzaot7dXVVVVmjt3Lis8AAC2FuuNrYbSd3LUGYr33ntPN954o2688UZJUnV1tW688UatWrVKSUlJ2rdvn/75n/9Z1113nRYtWqTJkyfrv/7rvyLSNc8995zGjBmj6dOn64477tCtt96q3/72t9F2BQCAocWiVR4Xayh9JzsMw347hwcCAbndbnV0dDCfAgBwQbH4zuj/jMINq+XMSB/0+4Q+71Lr/Wtt+f3GszwAALCM44ti5nx7IqAAAMAqgxi2OOd8m7rkqzwAAMDljwwFAABWSeAMBQEFAABWGcQTQ88536YIKAAAsEisnzY6lBBQAJcJIxRSsOez89YnpWXK4WDaFIBLg4ACuEx8/n+P69CLPz9PrUPj5z6itKwRMe0TkHCYQwHA7oK93TJCwXh3A0hsCTyHgvwncJkI9XbFuwsAEhgZCuAyEeztjncXgITnMM4WM+fbFQEFcJkIkqEA4i+B51Aw5AFcJkJkKADEERkK4DLBkAcwBCTwpEwCCuAyEWg9cN664XlXKyll8I9UBnCRGPIAYHd9XWfOW5eS6ZYjKSmGvQGQaMhQAAnAmZIqyb6pVMA2EjhDQUABJABnUirbbgOxQEAB4HLmTE6VHGQogEsugSdl8icLkACcyWlyEFAAuITIUACXAeNrnnnsTE6RGPIALjl2ygRgb0bogkGFI4l/6kBMJPAciqj+ZKmtrdVNN92krKws5ebmas6cOTp8+HBEm66uLvl8Po0YMULDhw9XZWWl2traItq0tLSooqJCmZmZys3N1YMPPqi+vj7zVwMkqFBfr2SELtiGIQ8Al1JUAUVjY6N8Pp927dqlhoYG9fb2asaMGers7Ay3Wb58uV555RVt2rRJjY2NOn78uO66665wfTAYVEVFhXp6evTOO+/o2Wef1caNG7Vq1SrrrgpIMKG+HhlfE1AAwKUUVR5069atEa83btyo3NxcNTc3a9q0aero6NDTTz+t+vp63X777ZKkZ555RmPHjtWuXbs0depUvfHGGzp06JC2bdumvLw8TZo0SY888ohWrFihNWvWKDU11bqrAxJEKNhLQAEMAQ6ZnENhWU9iz9QsrY6ODklSTk6OJKm5uVm9vb0qKysLtxkzZoyKiorU1NQkSWpqatL48eOVl5cXblNeXq5AIKCDBw8O+Dnd3d0KBAIRBcDfhfp6pBABBYD4GXRAEQqFtGzZMt1yyy0aN26cJMnv9ys1NVXZ2dkRbfPy8uT3+8NtvhxM9Nf31w2ktrZWbrc7XAoLCwfbbeCydDZDYePZXMDlon8fCjPFpgYdUPh8Ph04cEDPP/+8lf0ZUE1NjTo6OsKltbX1kn8mYCehPoY8gCHBsKDY1KDWklVVVWnLli3auXOnRo0aFT7u8XjU09OjU6dORWQp2tra5PF4wm3efffdiPfrXwXS3+ar0tLSlJaWNpiuAgnhTNvR8z4cLCXTrWFXXBnbDgFIOFFlKAzDUFVVlTZv3qwdO3Zo9OjREfWTJ09WSkqKtm/fHj52+PBhtbS0yOv1SpK8Xq/279+v9vb2cJuGhga5XC6VlJSYuRYgYYX6es67bNSRlKzktMwY9whIUGQoLo7P51N9fb1efvllZWVlhec8uN1uZWRkyO12a9GiRaqurlZOTo5cLpceeOABeb1eTZ06VZI0Y8YMlZSUaP78+Vq3bp38fr9Wrlwpn89HFgK4BByOpLPP8gBwybFT5kVav369JOm2226LOP7MM8/o3nvvlSQ99thjcjqdqqysVHd3t8rLy/XUU0+F2yYlJWnLli1aunSpvF6vhg0bpoULF+rhhx82dyUABuRwOuVISol3N4DEkMA7ZUYVUFzMLPL09HTV1dWprq7uvG2Ki4v16quvRvPRAAbJ4Uw6+ywPALiE2OAfuMw5HE45yVAAsUGGAoBdfW3m0ElAAcRKIs+h4HnGgO0ZMoLB89Y65JDDyT91AJcWGQrA5gzDUCjYE+9uAJDM73Zp450yCSgAuwuFzu5DASD+EngOBXlQwOYMg4ACQPyRoQDszggpFOyNdy8AKLEnZRJQADZnGAYZCmCoYMgDgF0ZRkih3gsEFA77TvICYB9kKACbC3ad0Rn/R+etz7lqcgx7AyQ4k0Meds5QEFAANmcYhozQ+fehSEobFsPeAAkugYc8CCiAy1xSSnq8uwAkjgQOKJhDAVzmnClp8e4CgARAhgK4zJGhAGInkZeNkqEALnPOlNR4dwFAAiCgAC5zSQx5AIgBhjwAm/vaXTId/N0AxEwCT8okoABsLtjbFe8uAPgCcygA2FaotzveXQAAMhSA3ZGhAIYYG2cZzCCgAGyODAUwhCTwHAqGPACbCxJQABgCogooamtrddNNNykrK0u5ubmaM2eODh8+HNHmtttuk8PhiCj3339/RJuWlhZVVFQoMzNTubm5evDBB9XX12f+aoAEFPj40HnrMkcUsmwUiKH+SZlmil1FNeTR2Ngon8+nm266SX19ffrpT3+qGTNm6NChQxo27O8PIFq8eLEefvjh8OvMzMzwz8FgUBUVFfJ4PHrnnXd04sQJLViwQCkpKfrFL35hwSUBiaWn8/+ety51eI4cSSkx7A2Q4BJ4yCOqgGLr1q0Rrzdu3Kjc3Fw1Nzdr2rRp4eOZmZnyeDwDvscbb7yhQ4cOadu2bcrLy9OkSZP0yCOPaMWKFVqzZo1SU9nVD7CKMzlVDocj3t0AEgbLRgepo6NDkpSTkxNx/LnnntPIkSM1btw41dTU6LPPPgvXNTU1afz48crLywsfKy8vVyAQ0MGDBwf8nO7ubgUCgYgC4Os5k1PZ2ApATAx6lUcoFNKyZct0yy23aNy4ceHj3/ve91RcXKyCggLt27dPK1as0OHDh/Xiiy9Kkvx+f0QwISn82u/3D/hZtbW1Wrt27WC7CiQsZ3IKGQoglhjyiJ7P59OBAwf09ttvRxxfsmRJ+Ofx48crPz9f06dP19GjR3X11VcP6rNqampUXV0dfh0IBFRYWDi4jgMJxJmcRoYCiKUEDigG9V+aqqoqbdmyRW+++aZGjRp1wbalpaWSpCNHjkiSPB6P2traItr0vz7fvIu0tDS5XK6IAuDrOZNT5BAZCuBytXPnTs2ePVsFBQVyOBx66aWXIuoNw9CqVauUn5+vjIwMlZWV6aOPPopoc/LkSc2bN08ul0vZ2dlatGiRzpw5E3VfogooDMNQVVWVNm/erB07dmj06NFfe87evXslSfn5+ZIkr9er/fv3q729PdymoaFBLpdLJSUl0XQHSHiGYVzwLxpnUorEkAcQM7FeNtrZ2amJEyeqrq5uwPp169bpiSee0IYNG7R7924NGzZM5eXl6ur6+w678+bN08GDB9XQ0KAtW7Zo586dEaMNFyuqIQ+fz6f6+nq9/PLLysrKCs95cLvdysjI0NGjR1VfX6877rhDI0aM0L59+7R8+XJNmzZNEyZMkCTNmDFDJSUlmj9/vtatWye/36+VK1fK5/MpLY318kA0jGCvZITO3+CLvWAAxEiMhzxmzZqlWbNmDfxWhqHHH39cK1eu1J133ilJ+v3vf6+8vDy99NJLmjt3rj744ANt3bpVe/bs0ZQpUyRJTz75pO644w798pe/VEFBwUX3JaoMxfr169XR0aHbbrtN+fn54fLCCy9IklJTU7Vt2zbNmDFDY8aM0Y9+9CNVVlbqlVdeCb9HUlKStmzZoqSkJHm9Xn3/+9/XggULIvatAHBxQn29Mi4UUABIWMeOHZPf71dZWVn4mNvtVmlpqZqamiSdXXmZnZ0dDiYkqaysTE6nU7t3747q86LKUBjGhUOnwsJCNTY2fu37FBcX69VXX43mowEMIBTslREioACGDIsyFF/dHiEtLS3qLH7/KMJAKyv76/x+v3JzcyPqk5OTlZOTc96Vl+fD9G/AxkJ9PWQogCHEqjkUhYWFcrvd4VJbWxvfC7sIPG0UsLHQ182hAGBLra2tESsaBzPHsH/lZFtbW3hhRP/rSZMmhdt8eZGEJPX19enkyZPnXXl5PmQoABsL9THkAQwphgVFOmerhMEEFKNHj5bH49H27dvDxwKBgHbv3i2v1yvp7MrLU6dOqbm5Odxmx44dCoVC4W0fLhYZCsDGOtuPqa/r9IB1yenDlTmCDeCAWIr1szzOnDkT3udJOjsRc+/evcrJyVFRUZGWLVumn/3sZ7r22ms1evRoPfTQQyooKNCcOXMkSWPHjtXMmTO1ePFibdiwQb29vaqqqtLcuXOjWuEhEVAAthbs+VxGKDhgnTM5RckZWTHuEZDgYrxs9L333tO3vvWt8Ov+XaUXLlyojRs36ic/+Yk6Ozu1ZMkSnTp1Srfeequ2bt2q9PT08DnPPfecqqqqNH36dDmdTlVWVuqJJ56IuusEFMDlypF0dmMrAJet22677YIrMB0Ohx5++OELbs2Qk5Oj+vp6030hoAAuUw6nU85kAgogphL4WR4EFMBlyuFwykGGAogpxxfFzPl2xSoP4DLlcDgZ8gAQM2QogMuVM0nO5NR49wJILAx5ALCbs08avfBkLIczKYY9AhDrZaNDCUMegF0ZhkLBngs24UmjAGKFDAVgU4YRUqivN97dAPBlDHkAsB0jpFDfhTMUAOLAxkGBGQQUwBBwoY1pLnTO1wUUg3lfhkkADAYBBTAEbN68WTU1NVGdk5GarMXl1+vma0cOWH/w4EHd9dMxUb1nbW2t7rrrrqjOAfB3iTwpk4ACGAICgYD++7//O6pzhmekqqercMCFHg6H1NXVFfV7BgKBqNoD+ArmUACwG9ewNE2+Ll+n+nL1P59PUmfQrWFJHboqY6+yk9u08//8Jd5dBBIOGQoAtuN0ONTpKNb/CUxXj5EhSeoMfkOnevM0MWu7Tp5+O849BJBI2IcCsKnPQ1n68+mycDDRr8fI0J9Pl+nTz9LPcyaAS8awoNgUGQrApgzDqd5QmgZalNEbSlNnVzD2nQISXCIPeZChAC5Tn3ez6RWA2IkqoFi/fr0mTJggl8sll8slr9er1157LVzf1dUln8+nESNGaPjw4aqsrFRbW1vEe7S0tKiiokKZmZnKzc3Vgw8+qL6+PmuuBkggqc7PlZvaonNzpIZyU1vU13s6Ht0CElsCD3lEFVCMGjVKjz76qJqbm/Xee+/p9ttv15133qmDBw9KkpYvX65XXnlFmzZtUmNjo44fPx6xpj0YDKqiokI9PT1655139Oyzz2rjxo1atWqVtVcFJIBkR48mZm2XJ/V/lOzolmQo2dEtT+r/aGLWDvX2dMa7i0DiSeCAIqo5FLNnz454/fOf/1zr16/Xrl27NGrUKD399NOqr6/X7bffLkl65plnNHbsWO3atUtTp07VG2+8oUOHDmnbtm3Ky8vTpEmT9Mgjj2jFihVas2aNUlOje9RyMBhUMMg4MewvFApFfc6pM116/I+NChr/n/7WO0rdoUylOT/TyJSPtc3Rp09OfTaofvBvCpcbfqdjY9CTMoPBoDZt2qTOzk55vV41Nzert7dXZWVl4TZjxoxRUVGRmpqaNHXqVDU1NWn8+PHKy8sLtykvL9fSpUt18OBB3XjjjQN+Vnd3t7q7u8Ov+zffWbx4sVJSUgZ7CcCQcezYsajPOfN5jza9deiLV/ss6cdvf/tbNTQ0WPJewFDR2xu7+USJPCkz6oBi//798nq96urq0vDhw7V582aVlJRo7969Sk1NVXZ2dkT7vLw8+f1+SZLf748IJvrr++vOp7a2VmvXrj3n+O9+9zu5XK5oLwEYcjZu3Kjdu3fHuxu6//77de+998a7G4ClAoGA/vM//zM2H5bAO2VGvcrj+uuv1969e7V7924tXbpUCxcu1KFDh77+RBNqamrU0dERLq2trZf08wAAQHSizlCkpqbqmmuukSRNnjxZe/bs0a9//Wvdfffd6unp0alTpyKyFG1tbfJ4PJIkj8ejd999N+L9+leB9LcZSFpamtLS0qLtKgAAMeUwDDkG8ZTfL59vV6b3oQiFQuru7tbkyZOVkpKi7du3h+sOHz6slpYWeb1eSZLX69X+/fvV3t4ebtPQ0CCXy6WSkhKzXQEAIL5Y5XFxampqNGvWLBUVFen06dOqr6/XW2+9pddff11ut1uLFi1SdXW1cnJy5HK59MADD8jr9Wrq1KmSpBkzZqikpETz58/XunXr5Pf7tXLlSvl8PjIQAADbY1LmRWpvb9eCBQt04sQJud1uTZgwQa+//rq+/e1vS5Iee+wxOZ1OVVZWqru7W+Xl5XrqqafC5yclJWnLli1aunSpvF6vhg0bpoULF+rhhx+29qoAAEBMRRVQPP300xesT09PV11dnerq6s7bpri4WK+++mo0HwsAgD0k8CoPHg4GAIBFEnnIg4eDAQAA08hQAENAUVGR5syZE+9uqKioKN5dAOyNIQ8A8XT77beHn4EDwL4Y8gAAADCBDAUAAFZhyAMAAFjBzsMWZjDkAQAATCNDAQCAVQzjbDFzvk0RUAAAYJFEXuVBQAEAgFUSeFImcygAAIBpZCgAALCII3S2mDnfrggoAACwCkMeAAAAg0eGAgAAi7DKAwAAmJfA+1Aw5AEAAEwjQwEAgEUY8gAAAOaxygMAAGDwyFAAAGCRRB7yiCpDsX79ek2YMEEul0sul0ter1evvfZauP62226Tw+GIKPfff3/Ee7S0tKiiokKZmZnKzc3Vgw8+qL6+PmuuBgCAeOpf5WGm2FRUGYpRo0bp0Ucf1bXXXivDMPTss8/qzjvv1J///GfdcMMNkqTFixfr4YcfDp+TmZkZ/jkYDKqiokIej0fvvPOOTpw4oQULFiglJUW/+MUvLLokAADiI5EzFFEFFLNnz454/fOf/1zr16/Xrl27wgFFZmamPB7PgOe/8cYbOnTokLZt26a8vDxNmjRJjzzyiFasWKE1a9YoNTV1kJcBAADiadCTMoPBoJ5//nl1dnbK6/WGjz/33HMaOXKkxo0bp5qaGn322WfhuqamJo0fP155eXnhY+Xl5QoEAjp48OB5P6u7u1uBQCCiAAAw5BgWFJuKelLm/v375fV61dXVpeHDh2vz5s0qKSmRJH3ve99TcXGxCgoKtG/fPq1YsUKHDx/Wiy++KEny+/0RwYSk8Gu/33/ez6ytrdXatWuj7SoAADHFkEcUrr/+eu3du1cdHR3605/+pIULF6qxsVElJSVasmRJuN348eOVn5+v6dOn6+jRo7r66qsH3cmamhpVV1eHXwcCARUWFg76/QAAgLWiDihSU1N1zTXXSJImT56sPXv26Ne//rV+85vfnNO2tLRUknTkyBFdffXV8ng8evfddyPatLW1SdJ5511IUlpamtLS0qLtKgAAsRUyzhYz59uU6Y2tQqGQuru7B6zbu3evJCk/P1+S5PV6tX//frW3t4fbNDQ0yOVyhYdNAACwLeZQXJyamhrNmjVLRUVFOn36tOrr6/XWW2/p9ddf19GjR1VfX6877rhDI0aM0L59+7R8+XJNmzZNEyZMkCTNmDFDJSUlmj9/vtatWye/36+VK1fK5/ORgQAAwMaiCija29u1YMECnThxQm63WxMmTNDrr7+ub3/722ptbdW2bdv0+OOPq7OzU4WFhaqsrNTKlSvD5yclJWnLli1aunSpvF6vhg0bpoULF0bsWwEAgF05ZHJSpmU9ib2oAoqnn376vHWFhYVqbGz82vcoLi7Wq6++Gs3HAgBgD2Z3u7TxTpk8HAwAAJjGw8EAALBIIu9DQYYCAACrxHiVx5o1a855KOeYMWPC9V1dXfL5fBoxYoSGDx+uysrK8HYNViOgAADAIg7DMF2idcMNN+jEiRPh8vbbb4frli9frldeeUWbNm1SY2Ojjh8/rrvuusvKSw5jyAMAABtLTk4ecHPIjo4OPf3006qvr9ftt98uSXrmmWc0duxY7dq1S1OnTrW0H2QoAACwSsiCIp3zQMzzbSApSR999JEKCgp01VVXad68eWppaZEkNTc3q7e3V2VlZeG2Y8aMUVFRkZqamiy9bImAAgAAy1g15FFYWCi32x0utbW1A35eaWmpNm7cqK1bt2r9+vU6duyYvvnNb+r06dPy+/1KTU1VdnZ2xDl5eXkXfCDnYDHkAQDAENPa2iqXyxV+fb7dpGfNmhX+ecKECSotLVVxcbH++Mc/KiMj45L388vIUAAAYBWLVnm4XK6IcrGPp8jOztZ1112nI0eOyOPxqKenR6dOnYpo09bWdsEHcg4WAQUAAFbp3ynTTDHhzJkzOnr0qPLz8zV58mSlpKRo+/bt4frDhw+rpaVFXq/X7JWegyEPAABs6sc//rFmz56t4uJiHT9+XKtXr1ZSUpLuueceud1uLVq0SNXV1crJyZHL5dIDDzwgr9dr+QoPiYACAADLxHqnzI8//lj33HOPPv30U11xxRW69dZbtWvXLl1xxRWSpMcee0xOp1OVlZXq7u5WeXm5nnrqqcF38AIIKAAAsEqMHw72/PPPX7A+PT1ddXV1qqurG3yfLhJzKAAAgGlkKAAAsIgjdLaYOd+uCCgAALBKjIc8hhICCgAArDKIJ4aec75NMYcCAACYRoYCAACLDPYR5F8+364IKAAAsEoCz6FgyAMAAJhGhgIAAKsYksws/bRvgoKAAgAAqyTyHAqGPAAAgGlkKAAAsIohk5MyLetJzNkyoDC++D8rEAjEuScAgKGu/7vCiMVwQgKv8rBlQPHpp59KkgoLC+PcEwCAXZw+fVputzve3bhs2TKgyMnJkSS1tLQk/C9HIBBQYWGhWltb5XK54t2duOE+nMV9OIv7cBb34SzDMHT69GkVFBRc+g8LSXKYPN+mbBlQOJ1n55K63e6E/kfyZS6Xi3sh7kM/7sNZ3IezuA+K2R+fibzKw5YBBQAAQ1ICz6Fg2SgAADDNlhmKtLQ0rV69WmlpafHuStxxL87iPpzFfTiL+3AW9yEOEjhD4TBiso4GAIDLVyAQkNvt1vSxP1Jy0uADuL5gt7Z/8P+qo6PDdvNeGPIAAACm2XLIAwCAIYllowAAwKxEXjbKkAcAADDNlgFFXV2drrzySqWnp6u0tFTvvvtuvLtkqZ07d2r27NkqKCiQw+HQSy+9FFFvGIZWrVql/Px8ZWRkqKysTB999FFEm5MnT2revHlyuVzKzs7WokWLdObMmRhehXm1tbW66aablJWVpdzcXM2ZM0eHDx+OaNPV1SWfz6cRI0Zo+PDhqqysVFtbW0SblpYWVVRUKDMzU7m5uXrwwQfV19cXy0sxZf369ZowYUJ4cyKv16vXXnstXJ8I92Agjz76qBwOh5YtWxY+lgj3Ys2aNXI4HBFlzJgx4fpEuAdDWv8qDzPFpmwXULzwwguqrq7W6tWr9f7772vixIkqLy9Xe3t7vLtmmc7OTk2cOFF1dXUD1q9bt05PPPGENmzYoN27d2vYsGEqLy9XV1dXuM28efN08OBBNTQ0aMuWLdq5c6eWLFkSq0uwRGNjo3w+n3bt2qWGhgb19vZqxowZ6uzsDLdZvny5XnnlFW3atEmNjY06fvy47rrrrnB9MBhURUWFenp69M477+jZZ5/Vxo0btWrVqnhc0qCMGjVKjz76qJqbm/Xee+/p9ttv15133qmDBw9KSox78FV79uzRb37zG02YMCHieKLcixtuuEEnTpwIl7fffjtclyj3YMgKGeaLXRk2c/PNNxs+ny/8OhgMGgUFBUZtbW0ce3XpSDI2b94cfh0KhQyPx2P8+7//e/jYqVOnjLS0NOMPf/iDYRiGcejQIUOSsWfPnnCb1157zXA4HMZf//rXmPXdau3t7YYko7Gx0TCMs9edkpJibNq0Kdzmgw8+MCQZTU1NhmEYxquvvmo4nU7D7/eH26xfv95wuVxGd3d3bC/AQt/4xjeM//iP/0jIe3D69Gnj2muvNRoaGox/+qd/Mn74wx8ahpE4vw+rV682Jk6cOGBdotyDoaijo8OQZJRdvcyYed2KQZeyq5cZkoyOjo54X1LUbJWh6OnpUXNzs8rKysLHnE6nysrK1NTUFMeexc6xY8fk9/sj7oHb7VZpaWn4HjQ1NSk7O1tTpkwJtykrK5PT6dTu3btj3merdHR0SPr7w+Gam5vV29sbcS/GjBmjoqKiiHsxfvx45eXlhduUl5crEAiE/8K3k2AwqOeff16dnZ3yer0JeQ98Pp8qKioirllKrN+Hjz76SAUFBbrqqqs0b948tbS0SEqsezBkJfCQh61Wefztb39TMBiM+IcgSXl5efrwww/j1KvY8vv9kjTgPeiv8/v9ys3NjahPTk5WTk5OuI3dhEIhLVu2TLfccovGjRsn6ex1pqamKjs7O6LtV+/FQPeqv84u9u/fL6/Xq66uLg0fPlybN29WSUmJ9u7dmzD3QJKef/55vf/++9qzZ885dYny+1BaWqqNGzfq+uuv14kTJ7R27Vp985vf1IEDBxLmHgxtZoMCAgrgkvL5fDpw4EDEWHEiuf7667V37151dHToT3/6kxYuXKjGxsZ4dyumWltb9cMf/lANDQ1KT0+Pd3fiZtasWeGfJ0yYoNLSUhUXF+uPf/yjMjIy4tgzSErorbdtNeQxcuRIJSUlnTNjua2tTR6PJ069iq3+67zQPfB4POdMUu3r69PJkydteZ+qqqq0ZcsWvfnmmxo1alT4uMfjUU9Pj06dOhXR/qv3YqB71V9nF6mpqbrmmms0efJk1dbWauLEifr1r3+dUPegublZ7e3t+sd//EclJycrOTlZjY2NeuKJJ5ScnKy8vLyEuRdflp2dreuuu05HjhxJqN8HDD22CihSU1M1efJkbd++PXwsFApp+/bt8nq9cexZ7IwePVoejyfiHgQCAe3evTt8D7xer06dOqXm5uZwmx07digUCqm0tDTmfR4swzBUVVWlzZs3a8eOHRo9enRE/eTJk5WSkhJxLw4fPqyWlpaIe7F///6IAKuhoUEul0slJSWxuZBLIBQKqbu7O6HuwfTp07V//37t3bs3XKZMmaJ58+aFf06Ue/FlZ86c0dGjR5Wfn59Qvw9DVgKv8rDdkEd1dbUWLlyoKVOm6Oabb9bjjz+uzs5O3XffffHummXOnDmjI0eOhF8fO3ZMe/fuVU5OjoqKirRs2TL97Gc/07XXXqvRo0froYceUkFBgebMmSNJGjt2rGbOnKnFixdrw4YN6u3tVVVVlebOnauCgoI4XVX0fD6f6uvr9fLLLysrKys8vut2u5WRkSG3261FixapurpaOTk5crlceuCBB+T1ejV16lRJ0owZM1RSUqL58+dr3bp18vv9WrlypXw+n22ewFhTU6NZs2apqKhIp0+fVn19vd566y29/vrrCXMPJCkrKys8f6bfsGHDNGLEiPDxRLgXP/7xjzV79mwVFxfr+PHjWr16tZKSknTPPfck1O/DkGWEzhYz59tVvJeZDMaTTz5pFBUVGampqcbNN99s7Nq1K95dstSbb75p6OzMnIiycOFCwzDOLh196KGHjLy8PCMtLc2YPn26cfjw4Yj3+PTTT4177rnHGD58uOFyuYz77rvPOH36dByuZvAGugeSjGeeeSbc5vPPPzd+8IMfGN/4xjeMzMxM47vf/a5x4sSJiPf53//9X2PWrFlGRkaGMXLkSONHP/qR0dvbG+OrGbx//dd/NYqLi43U1FTjiiuuMKZPn2688cYb4fpEuAfn8+Vlo4aRGPfi7rvvNvLz843U1FTjH/7hH4y7777bOHLkSLg+Ee7BUBReNlr0A2PmlcsHXcqKfmDbZaM8vhwAAJP6H19eVrhUyU4Tjy8PdWtb63pbPr7cdkMeAAAMWaH+ZKqZ8+3JVpMyAQDA0ESGAgAAqyTwPhQEFAAAWMWQyYDCsp7EHEMeAADANDIUAABYhSEPAABgWigkycTmVCH7bmxFQAEAgFUSOEPBHAoAAGAaGQoAAKySwBkKAgoAAKzCTpkAAACDR4YCAACLGEZIholHkJs5N94IKAAAsIphmBu2sPEcCoY8AACAaWQoAACwimFyUqaNMxQEFAAAWCUUkhwm5kHYeA4FQx4AAMA0MhQAAFiFIQ8AAGCWEQrJMDHkwbJRAACQ0BkK5lAAAADTyFAAAGCVkCE5EjNDQUABAIBVDEOSmWWj9g0oGPIAAACmkaEAAMAiRsiQYWLIwyBDAQAAZITMl0Goq6vTlVdeqfT0dJWWlurdd9+1+MK+HgEFAAA29sILL6i6ulqrV6/W+++/r4kTJ6q8vFzt7e0x7QcBBQAAFjFChukSrV/96ldavHix7rvvPpWUlGjDhg3KzMzU7373u0twhedHQAEAgFViPOTR09Oj5uZmlZWVhY85nU6VlZWpqanJ6qu7ICZlAgBgkT71mtoos0+9kqRAIBBxPC0tTWlpaee0/9vf/qZgMKi8vLyI43l5efrwww8H35FBIKAAAMCk1NRUeTweve1/1fR7DR8+XIWFhRHHVq9erTVr1ph+70uJgAIAAJPS09N17Ngx9fT0mH4vwzDkcDgijg2UnZCkkSNHKikpSW1tbRHH29ra5PF4TPclGgQUAABYID09Xenp6TH9zNTUVE2ePFnbt2/XnDlzJEmhUEjbt29XVVVVTPtCQAEAgI1VV1dr4cKFmjJlim6++WY9/vjj6uzs1H333RfTfhBQAABgY3fffbc++eQTrVq1Sn6/X5MmTdLWrVvPmah5qTkMO+/zCQAAhgT2oQAAAKYRUAAAANMIKAAAgGkEFAAAwDQCCgAAYBoBBQAAMI2AAgAAmEZAAQAATCOgAAAAphFQAAAA0wgoAACAaQQUAADAtP8fEqwen2oSVVgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(current_img_state)  # cmap='gray' for grayscale, remove for RGB\n",
    "plt.colorbar()  # Optionally display a colorbar\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d5c96b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T11:22:23.540267Z",
     "start_time": "2024-10-24T11:22:23.531438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0273956 , -0.00611216,  0.03585979,  0.0197368 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe8a19",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b310bf40978769ed8a86852a0458925e",
     "grade": true,
     "grade_id": "cell-1363692a5c2587c3",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Discuss the observations from your evaluation here.\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cadd2f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acf1aeab636ea5bae0cbb1b11848ba16",
     "grade": false,
     "grade_id": "cell-6be28454f1d2c5f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Combining Visual and Explicit State Information [30 points]\n",
    "\n",
    "Modify your implementation of the policy network so that it takes both the image and the explicit state information of the system as separate inputs (thus turning the policy into a multimodal policy). Then, update the learning loop accordingly and verify that learning is indeed taking place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded6a68",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec02c1fd7982dce782e2969b9941c842",
     "grade": true,
     "grade_id": "cell-019e9f9a3f567c09",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class UpdatedLearningAgent(nn.Module):\n",
    "    def __init__(self):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def sample_action(self):\n",
    "        \"\"\"Samples an action from the policy.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"Updates the network parameters.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d044c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b649aeb3fa58ebbe944bf1ebf60ac919",
     "grade": true,
     "grade_id": "cell-a04c1b0a08a24684",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# creating the cart pole environment in a way that allows us to render the observation as an image\n",
    "env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
    "\n",
    "### You can obtain an image of the current state of the system as follows:\n",
    "###     current_img_state = env.render()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d3d10a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e1d5fab13029132a89e6505cd2aaa1c",
     "grade": true,
     "grade_id": "cell-beb3f26bb8ee791f",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Has the second modality changed the behaviour of the agent? Discuss the observations from your evaluation here.\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
